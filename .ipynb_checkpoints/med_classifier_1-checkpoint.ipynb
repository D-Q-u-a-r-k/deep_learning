{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM File to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_PIL = True\n",
    "try:\n",
    "    import PIL.Image\n",
    "except ImportError:\n",
    "    have_PIL = False\n",
    "\n",
    "have_numpy = True\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    have_numpy = False\n",
    "\n",
    "\n",
    "def get_LUT_value(data, window, level):\n",
    "    \"\"\"Apply the RGB Look-Up Table for the given\n",
    "       data and window/level value.\"\"\"\n",
    "    if not have_numpy:\n",
    "        raise ImportError(\"Numpy is not available.\"\n",
    "                          \"See http://numpy.scipy.org/\"\n",
    "                          \"to download and install\")\n",
    "    try:\n",
    "        window = window[0]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        level = level[0]\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    return np.piecewise(data,\n",
    "                        [data <= (level - 0.5 - (window - 1) / 2),\n",
    "                         data > (level - 0.5 + (window - 1) / 2)],\n",
    "                        [0, 255, lambda data: ((data - (level - 0.5)) /\n",
    "                         (window - 1) + 0.5) * (255 - 0)])\n",
    "\n",
    "\n",
    "def get_PIL_image(dataset):\n",
    "    \"\"\"Get Image object from Python Imaging Library(PIL)\"\"\"\n",
    "    if not have_PIL:\n",
    "        raise ImportError(\"Python Imaging Library is not available. \"\n",
    "                          \"See http://www.pythonware.com/products/pil/ \"\n",
    "                          \"to download and install\")\n",
    "\n",
    "    if ('PixelData' not in dataset):\n",
    "        raise TypeError(\"Cannot show image -- DICOM dataset does not have \"\n",
    "                        \"pixel data\")\n",
    "    # can only apply LUT if these window info exists\n",
    "    if ('WindowWidth' not in dataset) or ('WindowCenter' not in dataset):\n",
    "        bits = dataset.BitsAllocated\n",
    "        samples = dataset.SamplesPerPixel\n",
    "        if bits == 8 and samples == 1:\n",
    "            mode = \"L\"\n",
    "        elif bits == 8 and samples == 3:\n",
    "            mode = \"RGB\"\n",
    "        elif bits == 16:\n",
    "            # not sure about this -- PIL source says is 'experimental'\n",
    "            # and no documentation. Also, should bytes swap depending\n",
    "            # on endian of file and system??\n",
    "            mode = \"I;16\"\n",
    "        else:\n",
    "            raise TypeError(\"Don't know PIL mode for %d BitsAllocated \"\n",
    "                            \"and %d SamplesPerPixel\" % (bits, samples))\n",
    "\n",
    "        # PIL size = (width, height)\n",
    "        size = (dataset.Columns, dataset.Rows)\n",
    "\n",
    "        # Recommended to specify all details\n",
    "        # by http://www.pythonware.com/library/pil/handbook/image.htm\n",
    "        im = PIL.Image.frombuffer(mode, size, dataset.PixelData,\n",
    "                                  \"raw\", mode, 0, 1)\n",
    "\n",
    "    else:\n",
    "        image = get_LUT_value(dataset.pixel_array, dataset.WindowWidth,\n",
    "                              dataset.WindowCenter)\n",
    "        # Convert mode to L since LUT has only 256 values:\n",
    "        #   http://www.pythonware.com/library/pil/handbook/image.htm\n",
    "        im = PIL.Image.fromarray(image).convert('L')\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def show_PIL(dataset):\n",
    "    \"\"\"Display an image using the Python Imaging Library (PIL)\"\"\"\n",
    "    im = get_PIL_image(dataset)\n",
    "     \n",
    "    im.show()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_list = os.listdir('./med_img/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in image_list:\n",
    "    try:\n",
    "        image_file = pydicom.read_file(\"med_img/train/\"+i)\n",
    "        image_array = show_PIL(image_file)\n",
    "        \n",
    "    except AttributeError:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('train data shape {} , test data shape {}'.format(train_x.shape, validate_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_function_factory(norm, relu, conv):\n",
    "    def bn_function(*inputs):\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = conv(relu(norm(concated_features)))\n",
    "        return bottleneck_output\n",
    "\n",
    "    return bn_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, efficient=False):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size * growth_rate,\n",
    "                        kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "        self.efficient = efficient\n",
    "\n",
    "    def forward(self, *prev_features):\n",
    "        bn_function = _bn_function_factory(self.norm1, self.relu1, self.conv1)\n",
    "        if self.efficient and any(prev_feature.requires_grad for prev_feature in prev_features):\n",
    "            bottleneck_output = cp.checkpoint(bn_function, *prev_features)\n",
    "        else:\n",
    "            bottleneck_output = bn_function(*prev_features)\n",
    "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, efficient=False):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bn_size=bn_size,\n",
    "                drop_rate=drop_rate,\n",
    "                efficient=efficient,\n",
    "            )\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "    def forward(self, init_features):\n",
    "        features = [init_features]\n",
    "        for name, layer in self.named_children():\n",
    "            new_features = layer(*features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 3 or 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "            (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "        small_inputs (bool) - set to True if images are 32x32. Otherwise assumes images are larger.\n",
    "        efficient (bool) - set to True to use checkpointing. Much more memory efficient, but slower.\n",
    "    \"\"\"\n",
    "    def __init__(self, growth_rate=12, block_config=(16, 16, 16), compression=0.5,\n",
    "                 num_init_features=24, bn_size=4, drop_rate=0,\n",
    "                 num_classes=10, small_inputs=True, efficient=False):\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "        assert 0 < compression <= 1, 'compression of densenet should be between 0 and 1'\n",
    "        self.avgpool_size = 8 if small_inputs else 7\n",
    "\n",
    "        # First convolution\n",
    "        if small_inputs:\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv0', nn.Conv2d(3, num_init_features, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ]))\n",
    "        else:\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ]))\n",
    "            self.features.add_module('norm0', nn.BatchNorm2d(num_init_features))\n",
    "            self.features.add_module('relu0', nn.ReLU(inplace=True))\n",
    "            self.features.add_module('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1,\n",
    "                                                           ceil_mode=False))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "                efficient=efficient,\n",
    "            )\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features,\n",
    "                                    num_output_features=int(num_features * compression))\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = int(num_features * compression)\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm_final', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Initialization\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'conv' in name and 'weight' in name:\n",
    "                n = param.size(0) * param.size(2) * param.size(3)\n",
    "                param.data.normal_().mul_(math.sqrt(2. / n))\n",
    "            elif 'norm' in name and 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            elif 'norm' in name and 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'classifier' in name and 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.avg_pool2d(out, kernel_size=self.avgpool_size).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(costs, accs):\n",
    "    '''\n",
    "    Plots curve of Cost vs epochs and Accuracy vs epochs for 'train' and 'valid' sets during training\n",
    "    '''\n",
    "    train_acc = accs['train']\n",
    "    valid_acc = accs['valid']\n",
    "    train_cost = costs['train']\n",
    "    valid_cost = costs['valid']\n",
    "    epochs = range(len(train_acc))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1,)\n",
    "    plt.plot(epochs, train_acc)\n",
    "    plt.plot(epochs, valid_acc)\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.title('Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_cost)\n",
    "    plt.plot(epochs, valid_cost)\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.title('Cost')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_p(x):\n",
    "    '''convert numpy float to Variable tensor float'''    \n",
    "    return Variable(torch.cuda.FloatTensor([x]), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(df, cat):\n",
    "    '''\n",
    "    Returns number of images in a study type dataframe which are of abnormal or normal\n",
    "    Args:\n",
    "    df -- dataframe\n",
    "    cat -- category, \"positive\" for abnormal and \"negative\" for normal\n",
    "    '''\n",
    "    return df[df['Path'].str.contains(cat)]['Count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torchnet import meter\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = ['train', 'valid'] # data categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, scheduler, \n",
    "                dataset_sizes, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    costs = {x:[] for x in data_cat} # for storing costs per epoch\n",
    "    accs = {x:[] for x in data_cat} # for storing accuracies per epoch\n",
    "    print('Train batches:', len(dataloaders['train']))\n",
    "    print('Valid batches:', len(dataloaders['valid']), '\\n')\n",
    "    for epoch in range(num_epochs):\n",
    "        confusion_matrix = {x: meter.ConfusionMeter(2, normalized=True) \n",
    "                            for x in data_cat}\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in data_cat:\n",
    "            model.train(phase=='train')\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                print(i, end='\\r')\n",
    "                inputs = data['images'][0]\n",
    "                labels = data['label'].type(torch.FloatTensor)\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                outputs = torch.mean(outputs)\n",
    "                loss = criterion(outputs, labels, phase)\n",
    "                running_loss += loss.data[0]\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # statistics\n",
    "                preds = (outputs.data > 0.5).type(torch.cuda.FloatTensor)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                confusion_matrix[phase].add(preds, labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            costs[phase].append(epoch_loss)\n",
    "            accs[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            print('Confusion Meter:\\n', confusion_matrix[phase].value())\n",
    "            # deep copy the model\n",
    "            if phase == 'valid':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Time elapsed: {:.0f}m {:.0f}s'.format(\n",
    "                time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "    plot_training(costs, accs)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, criterion, dataloaders, dataset_sizes, phase):\n",
    "    '''\n",
    "    Loops over phase (train or valid) set to determine acc, loss and \n",
    "    confusion meter of the model.\n",
    "    '''\n",
    "    confusion_matrix = meter.ConfusionMeter(2, normalized=True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for i, data in enumerate(dataloaders[phase]):\n",
    "        print(i, end='\\r')\n",
    "        labels = data['label'].type(torch.FloatTensor)\n",
    "        inputs = data['images'][0]\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.mean(outputs)\n",
    "        loss = criterion(outputs, labels, phase)\n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        preds = (outputs.data > 0.5).type(torch.cuda.FloatTensor)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        confusion_matrix.add(preds, labels.data)\n",
    "\n",
    "    loss = running_loss / dataset_sizes[phase]\n",
    "    acc = running_corrects / dataset_sizes[phase]\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, loss, acc))\n",
    "    print('Confusion Meter:\\n', confusion_matrix.value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = ['train', 'valid', 'test'] # data categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_level_data():\n",
    "    \"\"\"\n",
    "    Returns a dict, with keys 'train' and 'valid' and respective values as study level dataframes, \n",
    "    these dataframes contain three columns 'Path', 'Count', 'Label'\n",
    "    Args:\n",
    "        study_type (string): one of the seven study type folder names in 'train/valid/test' dataset \n",
    "    \"\"\"\n",
    "    study_data = {}\n",
    "    study_label = {'1': 1, '0': 0}\n",
    "    for phase in data_cat:\n",
    "        \n",
    "        BASE_DIR = \"med_img/{0}\".format(phase)\n",
    "        \n",
    "        study_data[phase] = pd.DataFrame(columns=['Path', 'Count', 'Label'])\n",
    "        \n",
    "        i = 0\n",
    "        #print(os.listdir(BASE_DIR))\n",
    "        for study in os.listdir(BASE_DIR): # for each study in that patient folder\n",
    "            label = study_label[(study.split('(')[1]).split(')')[0]] # get label 0 or 1\n",
    "            \n",
    "            path = BASE_DIR + '/' + study # path to this image\n",
    "            study_data[phase].loc[i] = [path, 1, label] # add new row\n",
    "            i+=1\n",
    "    #print(study_data)\n",
    "    return study_data\n",
    "#get_study_level_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset():\n",
    "    \"\"\"training dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        #Args:\n",
    "        #    df (pd.DataFrame): a pandas DataFrame with image path and labels.\n",
    "        #    transform (callable, optional): Optional transform to be applied\n",
    "        #        on a sample.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_path = self.df.iloc[idx, 0]\n",
    "        count = self.df.iloc[idx, 1]\n",
    "        images = []\n",
    "        for i in study_path:\n",
    "            image_file = pydicom.read_file(study_path)\n",
    "            image = get_PIL_image(image_file)\n",
    "            images.append(self.transform(image))\n",
    "        images = torch.stack(images)\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        sample = {'images': images, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(data, batch_size=8, study_level=False):\n",
    "    '''\n",
    "    Returns dataloader pipeline with data augmentation\n",
    "    '''\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    image_datasets = {x: ImageDataset(data[x], transform=data_transforms[x]) for x in data_cat}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in data_cat}\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### load data\n",
    "study_data = get_study_level_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Create dataloaders pipeline\n",
    "data_cat = ['train', 'valid', 'test'] # data categories\n",
    "dataloaders = get_dataloaders(study_data, batch_size=1) #### seee\n",
    "dataset_sizes = {x: len(study_data[x]) for x in data_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Build model\n",
    "# tai = total abnormal images, tni = total normal images\n",
    "tai = {x: get_count(study_data[x], '1') for x in data_cat}\n",
    "tni = {x: get_count(study_data[x], '0') for x in data_cat}\n",
    "Wt1 = {x: n_p(tni[x] / (tni[x] + tai[x])) for x in data_cat}\n",
    "Wt0 = {x: n_p(tai[x] / (tni[x] + tai[x])) for x in data_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tai:', tai)\n",
    "print('tni:', tni, '\\n')\n",
    "print('Wt0 train:', Wt0['train'])\n",
    "print('Wt0 valid:', Wt0['valid'])\n",
    "print('Wt1 train:', Wt1['train'])\n",
    "print('Wt1 valid:', Wt1['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(torch.nn.modules.Module):\n",
    "    def __init__(self, Wt1, Wt0):\n",
    "        super(Loss, self).__init__()\n",
    "        self.Wt1 = Wt1\n",
    "        self.Wt0 = Wt0\n",
    "        \n",
    "    def forward(self, inputs, targets, phase):\n",
    "        loss = - (self.Wt1[phase] * targets * inputs.log() + self.Wt0[phase] * (1 - targets) * (1 - inputs).log())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Loss(Wt1, Wt0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Train model\n",
    "model = train_model(model, criterion, optimizer, dataloaders, scheduler, dataset_sizes, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(model, criterion, dataloaders, dataset_sizes, phase='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(model, criterion, dataloaders, dataset_sizes, phase='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
